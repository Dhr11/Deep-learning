{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A2_T2_Dhruuv_DL.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fWD5F-Ffu279","colab_type":"text"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","\n","Dhruuv agarwal \n","\n","Denoising using 2D CNN by constructing images from signal info\n","\n"]},{"cell_type":"code","metadata":{"id":"97GUgGwRo2Vm","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLjPfr8vh_bf","colab_type":"code","colab":{}},"source":["def getSNR(yRawInpTimeDomain,yPredReadyToWrite):\n","    minLength = min(len(yRawInpTimeDomain),len(yPredReadyToWrite))\n","    clippedY_True = yRawInpTimeDomain[:minLength]\n","    clippedY_Pred = yPredReadyToWrite[:minLength]\n","    signal  = np.dot(clippedY_True,clippedY_True.T)\n","    subtract = clippedY_True - clippedY_Pred\n","    noise = np.dot(subtract,subtract.T)\n","    \n","    return 10*math.log10(signal/noise)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0Xfs0XOvIY0","colab_type":"text"},"source":["Here we get the files as given in the document and get the required input matrices after stft and absolute to get the magnitude.\n","\n","We then take the transpose of these matrices to match the format of Input matrix in the graph structure.\n"]},{"cell_type":"code","metadata":{"id":"K-mvETLG3-BI","colab_type":"code","outputId":"485bc73a-c4ba-4476-e8f4-244278d7f68f","colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["!pip install librosa # in colab, youâ€™ll need to install this\n","import librosa\n","s, sr=librosa.load('train_clean_male.wav', sr=None)\n","Sdata=librosa.stft(s, n_fft=1024, hop_length=512)\n","sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n","oXdata=librosa.stft(sn, n_fft=1024, hop_length=512)\n","Xdata = np.abs(oXdata.T)\n","Sdata = np.abs(Sdata.T)\n","\n","snt, srt=librosa.load('test_x_01.wav', sr=None)\n","Xtest=librosa.stft(snt, n_fft=1024, hop_length=512)\n","Xtestm = np.abs(Xtest.T)\n","\n","snt2, srt2=librosa.load('test_x_02.wav', sr=None)\n","Xtest2=librosa.stft(snt2, n_fft=1024, hop_length=512)\n","Xtestm2 = np.abs(Xtest2.T)\n","\n","print(Xdata.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n","Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n","Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n","(2459, 513)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjqmccYZ4QWe","colab_type":"code","colab":{}},"source":["Xinp = tf.placeholder('float',[None,20,513,1])\n","yinp = tf.placeholder('float',[None,513])\n","y = tf.placeholder('float')\n","is_training = tf.placeholder(tf.bool)\n","\n","from sklearn.model_selection import train_test_split\n","\n","#Xdata,Xval,Sdata,Sval = train_test_split(Xdata,Sdata,test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jZVrB_lp9mo","colab_type":"code","colab":{}},"source":["output = []\n","output2 = []\n","trainoutput=[]\n","batch_size = 10\n","\n","def cnn_model_fn(Xinp,yinp,mode):\n","  global output \n","  global output2\n","  global batch_size\n","  global trainoutput\n","\n","  \n","  input_layer = tf.reshape(Xinp, [-1, 20,513,1])\n","\n","  # Convolutional Layer #1\n","  conv1 = tf.layers.conv2d(\n","      inputs=input_layer,\n","      filters=16,\n","      kernel_size=[4, 4],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","  \n","  # Pooling Layer #1\n","  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=[2,2])#,data_format = 'channels_first')\n","\n","  # Convolutional Layer #2 and Pooling Layer #2\n","  conv2 = tf.layers.conv2d(\n","      inputs=pool1,\n","      filters=32,\n","      kernel_size=[2, 2],\n","      padding=\"same\",\n","      activation=tf.nn.relu\n","  )\n","  \n","  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=[2,2])#,data_format = 'channels_first')\n","  pool2_flat = tf.reshape(pool2, [-1, 1 *5* 128 * 32])\n","  #pool2_flat= tf.layers.flatten(pool2)#,data_format= 'channels_first')\n","\n","  dense = tf.layers.dense(inputs=pool2_flat, units=4048, activation=tf.nn.relu)#kernel_initializer=init,bias_initializer=init)#,data_format = 'channels_first')\n","  \n","  dropout = tf.layers.dropout(inputs=dense, rate=0.3,training=is_training)\n","  \n","  out = tf.layers.dense(inputs=dropout, units=513, activation=tf.nn.relu)#kernel_initializer=init,bias_initializer=init)\n","  \n","  mse = tf.losses.mean_squared_error(labels=yinp, predictions = out)\n","  \n","  \n","  # Configure the Training Op (for TRAIN mode)\n","  \n","  optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(mse)\n","    \n","  if mode == 'TRAIN':\n","    n_epochs = 200\n","\n","\n","    with tf.Session() as sess:\n","      sess.run(tf.global_variables_initializer())\n","      imageout = Sdata[19:,:]\n","      valimage = imageout[2420:,:]\n","      imageout = imageout[:2420,:]\n","      \n","      print(imageout[0].shape,valimage.shape)\n","      \n","      images1= np.array([ np.reshape(Xdata[j:j+20], (20, 513,1)) for j in range(2440)])\n","      print(imageout.shape,images1.shape)\n","      valimages = images1[2420:]\n","      images = images1[:2420]\n","      \n","      testimages1= np.array([ np.reshape(Xtestm[j:j+20], (20, 513,1)) for j in range(len(Xtestm)-19)])\n","      testimages2= np.array([ np.reshape(Xtestm2[j:j+20], (20, 513,1)) for j in range(len(Xtestm2)-19)])\n","      \n","      indices = [j for j in range(0,2440)]\n","      for epoch in range(n_epochs):\n","        tempout=[]\n","        res=[]\n","        loss = 0\n","        for i in range(0,int(2420/batch_size)):   \n","          xbatch = images[i*batch_size:(i+1)*batch_size]\n","          sbatch = imageout[i*batch_size:(i+1)*batch_size,:]\n","          last= (i+1)*batch_size\n","   \n","          res = sess.run([optimizer,mse],feed_dict={Xinp:xbatch,yinp:sbatch,is_training:True})\n","          loss += res[1]\n","          \n","        xbatch = images[last:]\n","        sbatch = imageout[last:]\n","        #sbatch = np.reshape(sbatch, [1, 513])\n","        \n","        if len(xbatch) >1:\n","          res = sess.run([optimizer,mse],feed_dict={Xinp:xbatch,yinp:sbatch,is_training:True})\n","          loss += res[1]\n","          #tempout.append(res[2])\n","        tempout = sess.run(out,feed_dict = {Xinp:images1, is_training:False})\n","        rows = []\n","        for j in range(0,19):\n","          row = [np.random.random()/1000 for i in range(0,513)]\n","          rows.append(row)\n","        rows=np.array(rows)  \n","        tempout = np.concatenate((rows,tempout),axis=0)\n","        sht = (oXdata/Xdata.T)*tempout.T\n","        iSt = librosa.istft(sht, hop_length=512)\n","        \n","        print(\"snr:\", getSNR(s,iSt))\n","        loss = loss/(int(2420/batch_size))\n","        resv = sess.run([optimizer,mse],feed_dict={Xinp:valimages,yinp:valimage,is_training:False})    \n","        print('Epoch',epoch,' out of ',n_epochs)#,' loss:',loss,\" \",resv[1])\n","        \n","      \n","      output = sess.run(out,feed_dict = {Xinp:testimages1, is_training:False})  \n","      output2=sess.run(out,feed_dict = {Xinp:testimages2, is_training:False}) \n","       "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EVswDidWT1I","colab_type":"code","outputId":"9af8e9ad-453a-4aa3-ce3b-35e9d703c7db","colab":{"base_uri":"https://localhost:8080/","height":7143}},"source":["#setparam(2,1024,513,513,100)\n","cnn_model_fn(Xinp,yinp,'TRAIN')\n","#print(output2.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-90de2d8557d9>:22: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.conv2d instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-6-90de2d8557d9>:29: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.max_pooling2d instead.\n","WARNING:tensorflow:From <ipython-input-6-90de2d8557d9>:47: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:From <ipython-input-6-90de2d8557d9>:49: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","(513,) (20, 513)\n","(2420, 513) (2440, 20, 513, 1)\n","2.395818836212312\n","Epoch 0  out of  200  loss: 0.07954061189819125   0.019349078\n","3.7349354580095673\n","Epoch 1  out of  200  loss: 0.0587290790812674   0.018004125\n","5.1348441227166655\n","Epoch 2  out of  200  loss: 0.043505569014959   0.013986467\n","6.038109560187035\n","Epoch 3  out of  200  loss: 0.03356647283283016   0.009627054\n","6.680919694993499\n","Epoch 4  out of  200  loss: 0.027830216745562873   0.006066839\n","6.237181205806648\n","Epoch 5  out of  200  loss: 0.02491820599889928   0.0059264004\n","7.702546336956264\n","Epoch 6  out of  200  loss: 0.02180932180646387   0.0052202833\n","8.2594872669133\n","Epoch 7  out of  200  loss: 0.018549409134254895   0.0041024494\n","8.183104149561167\n","Epoch 8  out of  200  loss: 0.01732113914252949   0.0043976917\n","9.03256246624047\n","Epoch 9  out of  200  loss: 0.015730072462893752   0.0035129064\n","9.067053520435561\n","Epoch 10  out of  200  loss: 0.014201901873168613   0.0032900786\n","9.667274965988733\n","Epoch 11  out of  200  loss: 0.012785682388785663   0.0030410786\n","10.27528370344882\n","Epoch 12  out of  200  loss: 0.011692725262352821   0.002718946\n","10.477493906051091\n","Epoch 13  out of  200  loss: 0.01084580418584424   0.002570731\n","10.389549852478982\n","Epoch 14  out of  200  loss: 0.010353120879646802   0.002607837\n","10.660884685743158\n","Epoch 15  out of  200  loss: 0.0100302580359154   0.0023589472\n","10.87033999016359\n","Epoch 16  out of  200  loss: 0.009464543295237016   0.002272396\n","11.242331127422819\n","Epoch 17  out of  200  loss: 0.008917517187557287   0.0020331317\n","11.066794104668372\n","Epoch 18  out of  200  loss: 0.008634020466589459   0.001954066\n","11.829550648951523\n","Epoch 19  out of  200  loss: 0.00805104910251272   0.0019283354\n","12.149733242489889\n","Epoch 20  out of  200  loss: 0.007339146149882983   0.0015456366\n","12.238840358638068\n","Epoch 21  out of  200  loss: 0.007036957865772617   0.0015730428\n","12.114577173033215\n","Epoch 22  out of  200  loss: 0.006912902622862622   0.0016412293\n","11.206935173266137\n","Epoch 23  out of  200  loss: 0.00721278104569032   0.0019514242\n","11.618939721223818\n","Epoch 24  out of  200  loss: 0.0066796839547794305   0.0019064809\n","12.981777494293784\n","Epoch 25  out of  200  loss: 0.00632142676807813   0.0012994155\n","12.731950850309179\n","Epoch 26  out of  200  loss: 0.005965725307301789   0.0013638578\n","13.039293405064853\n","Epoch 27  out of  200  loss: 0.005880821762572347   0.0013913526\n","12.133456792233545\n","Epoch 28  out of  200  loss: 0.005880987972150326   0.001790037\n","11.470076222836108\n","Epoch 29  out of  200  loss: 0.006734738562917007   0.0018903718\n","11.456802587142406\n","Epoch 30  out of  200  loss: 0.006237523675630925   0.0022462248\n","12.347238355492266\n","Epoch 31  out of  200  loss: 0.005828802236502563   0.0011286872\n","12.593808228757897\n","Epoch 32  out of  200  loss: 0.005158329892975785   0.001278225\n","13.806433913328185\n","Epoch 33  out of  200  loss: 0.004663457329540453   0.0010052642\n","14.11743703318928\n","Epoch 34  out of  200  loss: 0.004346276768407455   0.00091370795\n","13.958340137809472\n","Epoch 35  out of  200  loss: 0.004328456577466508   0.00088572904\n","13.257801352623606\n","Epoch 36  out of  200  loss: 0.004628198959407133   0.0011166844\n","12.224080563700891\n","Epoch 37  out of  200  loss: 0.005132114050543013   0.0016653645\n","11.873984573108224\n","Epoch 38  out of  200  loss: 0.005950497223336641   0.0011540627\n","12.104961354406614\n","Epoch 39  out of  200  loss: 0.005269445889090762   0.0014973163\n","13.765812240872691\n","Epoch 40  out of  200  loss: 0.004603477932798627   0.0011729823\n","13.616975461274423\n","Epoch 41  out of  200  loss: 0.004068993117471109   0.0010701602\n","14.309734661973632\n","Epoch 42  out of  200  loss: 0.0039335401006384985   0.0008860668\n","14.210141674368678\n","Epoch 43  out of  200  loss: 0.0038551609081803103   0.00073074916\n","14.396975571485779\n","Epoch 44  out of  200  loss: 0.003768851335817916   0.00070978847\n","14.62430816496267\n","Epoch 45  out of  200  loss: 0.003595302943722345   0.0007052547\n","14.650460586258166\n","Epoch 46  out of  200  loss: 0.003465797022576872   0.00069378805\n","14.679087535830913\n","Epoch 47  out of  200  loss: 0.0034604663887274766   0.0008553183\n","13.777442875239034\n","Epoch 48  out of  200  loss: 0.0036132946240121037   0.0012127038\n","14.117808063997844\n","Epoch 49  out of  200  loss: 0.0036115105221525925   0.00083854946\n","13.579281474785223\n","Epoch 50  out of  200  loss: 0.00353924758917495   0.0009564273\n","14.261288230077794\n","Epoch 51  out of  200  loss: 0.003528423223798192   0.0009840728\n","14.393680253278456\n","Epoch 52  out of  200  loss: 0.003432643020756992   0.0007589218\n","14.787817914604187\n","Epoch 53  out of  200  loss: 0.0034659818052468158   0.0007160377\n","14.289153877999855\n","Epoch 54  out of  200  loss: 0.003488986346341831   0.00094474945\n","13.29309067951258\n","Epoch 55  out of  200  loss: 0.003509671129829581   0.0013211557\n","14.475652706970907\n","Epoch 56  out of  200  loss: 0.0036381396261133863   0.00079010066\n","14.472187925531731\n","Epoch 57  out of  200  loss: 0.0033045590602950527   0.00095748715\n","14.821693451177627\n","Epoch 58  out of  200  loss: 0.0030393098288735297   0.0008099032\n","14.328327963097138\n","Epoch 59  out of  200  loss: 0.0031217953117312607   0.0007987131\n","15.2263194254178\n","Epoch 60  out of  200  loss: 0.002931535201906995   0.0006344348\n","15.159762542049815\n","Epoch 61  out of  200  loss: 0.002844841912553593   0.00053194485\n","15.074113806393086\n","Epoch 62  out of  200  loss: 0.0028480313518297754   0.00057331077\n","15.12370769452672\n","Epoch 63  out of  200  loss: 0.0028110216160652166   0.00069414766\n","14.10062011088683\n","Epoch 64  out of  200  loss: 0.0029562186688046254   0.0008696163\n","13.983181684463243\n","Epoch 65  out of  200  loss: 0.0033754064102478787   0.0008512654\n","13.408608061493563\n","Epoch 66  out of  200  loss: 0.003670856026278783   0.0010423713\n","13.937559971631826\n","Epoch 67  out of  200  loss: 0.0038476937391178504   0.0008481064\n","14.0792110141283\n","Epoch 68  out of  200  loss: 0.0032179008891891634   0.00095124345\n","15.030673590843593\n","Epoch 69  out of  200  loss: 0.0029253256058690423   0.0007102966\n","14.478433353954703\n","Epoch 70  out of  200  loss: 0.0030267584058270764   0.0008668643\n","14.604662782403523\n","Epoch 71  out of  200  loss: 0.0029273674003701114   0.00066269655\n","14.545550730228669\n","Epoch 72  out of  200  loss: 0.0027477231032854202   0.0007166317\n","15.269082774505225\n","Epoch 73  out of  200  loss: 0.0026702152113892014   0.0006675362\n","14.954089909014648\n","Epoch 74  out of  200  loss: 0.0025380492625850623   0.00067257014\n","15.148201465623213\n","Epoch 75  out of  200  loss: 0.002565172260207971   0.0006647698\n","15.003376946408322\n","Epoch 76  out of  200  loss: 0.002476629882898319   0.00063650555\n","15.489515642314105\n","Epoch 77  out of  200  loss: 0.0024321379026347612   0.000525297\n","15.335803698888329\n","Epoch 78  out of  200  loss: 0.002381471208104625   0.00059736206\n","14.805020364806989\n","Epoch 79  out of  200  loss: 0.002525350629804796   0.00067138096\n","13.90181941303603\n","Epoch 80  out of  200  loss: 0.002908690325698031   0.0010787501\n","15.04380198506972\n","Epoch 81  out of  200  loss: 0.0028328609946396124   0.000607059\n","15.181472523582897\n","Epoch 82  out of  200  loss: 0.002497922685888099   0.0006770359\n","15.680048005475506\n","Epoch 83  out of  200  loss: 0.0023592121526126142   0.0004632921\n","15.734889004951773\n","Epoch 84  out of  200  loss: 0.0022303237348792622   0.00040066428\n","15.869281510520732\n","Epoch 85  out of  200  loss: 0.0022966954946932973   0.00037696364\n","15.743966487065308\n","Epoch 86  out of  200  loss: 0.0022994491623987323   0.0003965915\n","15.556065427748331\n","Epoch 87  out of  200  loss: 0.002319844179701926   0.00045789167\n","15.193533271033502\n","Epoch 88  out of  200  loss: 0.0024928139282170483   0.00050961616\n","15.009654001700603\n","Epoch 89  out of  200  loss: 0.002469210494886028   0.0004197229\n","15.482387938228857\n","Epoch 90  out of  200  loss: 0.0021830715183459837   0.00043929112\n","15.946480541514026\n","Epoch 91  out of  200  loss: 0.002224398732118783   0.000416609\n","15.6953136153276\n","Epoch 92  out of  200  loss: 0.0021242727726034486   0.00043815703\n","16.04198160251084\n","Epoch 93  out of  200  loss: 0.0021473433227831924   0.0003465223\n","15.661137009614382\n","Epoch 94  out of  200  loss: 0.0022042892297625912   0.00042943063\n","15.085780046545134\n","Epoch 95  out of  200  loss: 0.0023647000994229486   0.00045508367\n","14.493491630918228\n","Epoch 96  out of  200  loss: 0.0025216109074452197   0.0006834383\n","15.792315641638488\n","Epoch 97  out of  200  loss: 0.002372707790161355   0.00043143315\n","15.286372159125898\n","Epoch 98  out of  200  loss: 0.0022994759411698743   0.00047104986\n","15.091810718705732\n","Epoch 99  out of  200  loss: 0.002426676465926324   0.0005116433\n","14.921167337073967\n","Epoch 100  out of  200  loss: 0.0023074336739318073   0.0006547812\n","15.026306590725104\n","Epoch 101  out of  200  loss: 0.0025123649021179893   0.00051793124\n","14.845611122656592\n","Epoch 102  out of  200  loss: 0.0023782737509956244   0.0005609913\n","16.162184827664994\n","Epoch 103  out of  200  loss: 0.002053538869539589   0.00038673263\n","16.341932547263728\n","Epoch 104  out of  200  loss: 0.001912945006969201   0.00029148982\n","16.30941932014666\n","Epoch 105  out of  200  loss: 0.0018803105122398758   0.00029150082\n","15.805251656159484\n","Epoch 106  out of  200  loss: 0.0019496790916702052   0.0003650774\n","15.601715617573728\n","Epoch 107  out of  200  loss: 0.002026800620455076   0.00034306973\n","16.243658908989815\n","Epoch 108  out of  200  loss: 0.002065403056119916   0.00030037967\n","15.594940700922624\n","Epoch 109  out of  200  loss: 0.002086383625141972   0.00040767615\n","14.526081136701814\n","Epoch 110  out of  200  loss: 0.0024336460456983   0.0007921676\n","14.768306548257538\n","Epoch 111  out of  200  loss: 0.0025878469810300163   0.0007069664\n","15.149672579509634\n","Epoch 112  out of  200  loss: 0.002246324433513072   0.00068826287\n","15.703006553575365\n","Epoch 113  out of  200  loss: 0.002002483399649441   0.00048872357\n","15.720734551613473\n","Epoch 114  out of  200  loss: 0.001894865076333979   0.00042935784\n","16.37098143825582\n","Epoch 115  out of  200  loss: 0.001781080242125434   0.00026814692\n","16.36245590629629\n","Epoch 116  out of  200  loss: 0.001731711254386719   0.0002935279\n","16.23369069209562\n","Epoch 117  out of  200  loss: 0.0017445287920445254   0.00025325664\n","15.988462635156894\n","Epoch 118  out of  200  loss: 0.0018973945312902574   0.00027044053\n","15.900410893369232\n","Epoch 119  out of  200  loss: 0.0019501437952821415   0.00028875188\n","16.224269064096884\n","Epoch 120  out of  200  loss: 0.0018306005661313915   0.00025020432\n","16.051814871079195\n","Epoch 121  out of  200  loss: 0.0018431493184109494   0.0002485496\n","15.585606412141557\n","Epoch 122  out of  200  loss: 0.0020082138361645356   0.00031022655\n","15.392099358571523\n","Epoch 123  out of  200  loss: 0.002003879778173113   0.0006200328\n","15.81293059708713\n","Epoch 124  out of  200  loss: 0.001909267103274559   0.00028297195\n","16.260842197752233\n","Epoch 125  out of  200  loss: 0.0017885639836940528   0.00029586875\n","16.43328707365008\n","Epoch 126  out of  200  loss: 0.0017282630079076505   0.0002182663\n","16.063397979452084\n","Epoch 127  out of  200  loss: 0.0017260143224697728   0.00025386328\n","16.234081863801116\n","Epoch 128  out of  200  loss: 0.001840813931813718   0.00026735273\n","16.218184644324317\n","Epoch 129  out of  200  loss: 0.0017780339628925429   0.00024730523\n","16.155458690372335\n","Epoch 130  out of  200  loss: 0.0018393904916810852   0.0002655535\n","16.261463293249808\n","Epoch 131  out of  200  loss: 0.0018152385283496534   0.0002669281\n","15.431048117794393\n","Epoch 132  out of  200  loss: 0.0019207141702973177   0.00035178178\n","15.771115474169829\n","Epoch 133  out of  200  loss: 0.0018567753000989188   0.00033060092\n","15.83670301635114\n","Epoch 134  out of  200  loss: 0.0018626835436061661   0.00028301193\n","15.90138884054525\n","Epoch 135  out of  200  loss: 0.0020338765409201   0.00030265457\n","15.862169468723923\n","Epoch 136  out of  200  loss: 0.0018521082913537626   0.00024946049\n","16.039032141703505\n","Epoch 137  out of  200  loss: 0.0017073833913167438   0.0002892384\n","16.04449740899812\n","Epoch 138  out of  200  loss: 0.0017755693886687938   0.00022423023\n","15.8903952365338\n","Epoch 139  out of  200  loss: 0.001769243820261121   0.00026917728\n","15.580086314360958\n","Epoch 140  out of  200  loss: 0.0017588462331460046   0.000351056\n","14.978588808585076\n","Epoch 141  out of  200  loss: 0.002058878342029496   0.00050541863\n","15.715235703543938\n","Epoch 142  out of  200  loss: 0.002085777320847356   0.00048408675\n","15.343774656659592\n","Epoch 143  out of  200  loss: 0.0020125951336396144   0.00047442844\n","15.353064750963155\n","Epoch 144  out of  200  loss: 0.0019719217237286276   0.0004844762\n","15.577916209283371\n","Epoch 145  out of  200  loss: 0.0017433519191219287   0.00048051387\n","16.122677501594197\n","Epoch 146  out of  200  loss: 0.0017098370113664474   0.0002682254\n","16.119023245396473\n","Epoch 147  out of  200  loss: 0.0016799531412691202   0.00028711217\n","16.680735053625252\n","Epoch 148  out of  200  loss: 0.0015352714237304866   0.00021740633\n","16.568005727582065\n","Epoch 149  out of  200  loss: 0.001536241231998089   0.0002228302\n","16.64736175023814\n","Epoch 150  out of  200  loss: 0.0014829616751503335   0.00020382878\n","16.359672269030177\n","Epoch 151  out of  200  loss: 0.0015406052013150274   0.00020006103\n","16.294494047934517\n","Epoch 152  out of  200  loss: 0.0015082262345612817   0.0002568655\n","16.54048086235586\n","Epoch 153  out of  200  loss: 0.0014913152365784487   0.00019230712\n","16.1707026112082\n","Epoch 154  out of  200  loss: 0.0015872755483737706   0.00020117073\n","16.27375835763077\n","Epoch 155  out of  200  loss: 0.0017999581498541314   0.00024184637\n","16.38236336324467\n","Epoch 156  out of  200  loss: 0.0017135000117426643   0.0002272891\n","16.105842567673925\n","Epoch 157  out of  200  loss: 0.001713393908119557   0.00027360232\n","15.613143996583101\n","Epoch 158  out of  200  loss: 0.0018996185662149964   0.00025093424\n","15.984766716312746\n","Epoch 159  out of  200  loss: 0.001978825766977295   0.00026913924\n","16.53290887114345\n","Epoch 160  out of  200  loss: 0.0016114562167316281   0.00020053226\n","16.313566982743065\n","Epoch 161  out of  200  loss: 0.0016362257225909695   0.00023379043\n","16.58932710176974\n","Epoch 162  out of  200  loss: 0.0016975777862359438   0.00022478252\n","16.555772097864494\n","Epoch 163  out of  200  loss: 0.0016051141189924868   0.00019312609\n","16.62969081826969\n","Epoch 164  out of  200  loss: 0.0015035310762983528   0.00020002895\n","16.631097742242957\n","Epoch 165  out of  200  loss: 0.0014869222775792156   0.00019720235\n","16.68333922999143\n","Epoch 166  out of  200  loss: 0.001495492294644231   0.00019683615\n","16.19464599689828\n","Epoch 167  out of  200  loss: 0.0015113913551254687   0.00022765709\n","16.34466376535963\n","Epoch 168  out of  200  loss: 0.0016647076131749217   0.0002679929\n","16.420466870067827\n","Epoch 169  out of  200  loss: 0.001558090894945023   0.00024519986\n","16.156555482626153\n","Epoch 170  out of  200  loss: 0.0014939138020414878   0.0002368613\n","16.41659402211435\n","Epoch 171  out of  200  loss: 0.0014876653880950591   0.00017715833\n","16.309952525168097\n","Epoch 172  out of  200  loss: 0.001544226974300171   0.00024855067\n","16.121028630543254\n","Epoch 173  out of  200  loss: 0.0015076576769463505   0.00022309454\n","16.77236006346446\n","Epoch 174  out of  200  loss: 0.0014761292566821012   0.00017588107\n","16.67295199088664\n","Epoch 175  out of  200  loss: 0.0014660285239614503   0.00022528753\n","16.61704621919035\n","Epoch 176  out of  200  loss: 0.0013897355138425148   0.00020256768\n","16.116190488386476\n","Epoch 177  out of  200  loss: 0.0015051820801147173   0.0001735983\n","16.273308612609583\n","Epoch 178  out of  200  loss: 0.001524488860456195   0.00018426143\n","16.675282995723006\n","Epoch 179  out of  200  loss: 0.001536151022950555   0.00020630444\n","16.098787722444502\n","Epoch 180  out of  200  loss: 0.001499462763769605   0.00022726314\n","16.01010487492491\n","Epoch 181  out of  200  loss: 0.0016006329878060824   0.00025513794\n","16.51595733067149\n","Epoch 182  out of  200  loss: 0.0015527011703632765   0.00018786118\n","16.661541178192138\n","Epoch 183  out of  200  loss: 0.0014620016905245552   0.00017512351\n","16.169908329881054\n","Epoch 184  out of  200  loss: 0.0015232551158499345   0.00023832833\n","15.722032867402255\n","Epoch 185  out of  200  loss: 0.0015672425306641623   0.00023307557\n","16.061513506959532\n","Epoch 186  out of  200  loss: 0.001580087488844974   0.00025184322\n","16.65619519258875\n","Epoch 187  out of  200  loss: 0.0015077655630644465   0.00020273584\n","16.459888215605854\n","Epoch 188  out of  200  loss: 0.001520499064261172   0.0001818176\n","15.995442651120655\n","Epoch 189  out of  200  loss: 0.0016157402926628192   0.00023343327\n","16.150266044824466\n","Epoch 190  out of  200  loss: 0.0015499294644483552   0.00031681484\n","16.4973557337954\n","Epoch 191  out of  200  loss: 0.0016942037257908964   0.00024338535\n","16.815149211234125\n","Epoch 192  out of  200  loss: 0.001459771737666242   0.00026076965\n","16.825887700028737\n","Epoch 193  out of  200  loss: 0.001311907488089741   0.00016125366\n","16.52702760466417\n","Epoch 194  out of  200  loss: 0.0013608070488215552   0.00016462464\n","16.429532703348087\n","Epoch 195  out of  200  loss: 0.0013927145826242804   0.00018348711\n","16.575723125955747\n","Epoch 196  out of  200  loss: 0.00144076748242997   0.00017686894\n","16.69749684869479\n","Epoch 197  out of  200  loss: 0.0014062143775766547   0.00016510075\n","16.282397232824334\n","Epoch 198  out of  200  loss: 0.0015260194824244806   0.0002080099\n","15.988992095302386\n","Epoch 199  out of  200  loss: 0.001752792293881018   0.00029829817\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VK7-RLs9wVTg","colab_type":"text"},"source":["We see the SNR ends up to be 16 approx in about 200 epochs only.  \n","\n","Also as we needed positive values at the end we have chosen relu activation at the last layer. \n","The structure is 2 conv layer (16 filters of 4x4 and 32 filters of 2x2 ) with maxpooling after both,followed by 1 dense layer with dropout then output layer.  And the the leanrning rate was selected to be 0.0001. \n","\n","After this we get the Matrices learnt from the trained model and the Test input data, and convert them to get back the phase information as below.\n","\n","This enables us to use istft and get the reconstructed version of the sound signal."]},{"cell_type":"code","metadata":{"id":"_f_-pB5hBVcZ","colab_type":"code","colab":{}},"source":["rows = []\n","for j in range(0,19):\n","  row = [np.random.random()/1000 for i in range(0,513)]\n","  rows.append(row)\n","rows=np.array(rows)  \n","final = np.concatenate((rows,output),axis=0)\n","shtest1 = (Xtest/Xtestm.T)*final.T\n","final2 = np.concatenate((rows,output2),axis=0)\n","shtest2 = (Xtest2/Xtestm2.T)*final2.T\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KiCGEMYYSTEF","colab":{}},"source":["iStftMat1 = librosa.istft(shtest1, hop_length=512)\n","iStftMat2 = librosa.istft(shtest2, hop_length=512)\n","\n","librosa.output.write_wav('test_s_01_recons.wav', iStftMat1, srt)\n","librosa.output.write_wav('test_s_02_recons.wav', iStftMat2, srt2)"],"execution_count":0,"outputs":[]}]}