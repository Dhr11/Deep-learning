{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A2_T1_Dhruuv_DL.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fWD5F-Ffu279","colab_type":"text"},"source":["\n","\n","\n","Dhruuv agarwal \n","\n","Denoising using 1d CNN\n","\n"]},{"cell_type":"code","metadata":{"id":"97GUgGwRo2Vm","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbEoDt1cq9vp","colab_type":"code","colab":{}},"source":["def getSNR(yRawInpTimeDomain,yPredReadyToWrite):\n","    minLength = min(len(yRawInpTimeDomain),len(yPredReadyToWrite))\n","    clippedY_True = yRawInpTimeDomain[:minLength]\n","    clippedY_Pred = yPredReadyToWrite[:minLength]\n","    signal  = np.dot(clippedY_True,clippedY_True.T)\n","    subtract = clippedY_True - clippedY_Pred\n","    noise = np.dot(subtract,subtract.T)\n","    \n","    return 10*math.log10(signal/noise)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0Xfs0XOvIY0","colab_type":"text"},"source":["Here we get the files as given in the document and get the required input matrices after stft and absolute to get the magnitude.\n","\n","We then take the transpose of these matrices to match the format of Input matrix in the graph structure.\n"]},{"cell_type":"code","metadata":{"id":"K-mvETLG3-BI","colab_type":"code","outputId":"93014a83-446a-4aae-df9d-53a5743aaea5","executionInfo":{"status":"error","timestamp":1558129223912,"user_tz":240,"elapsed":6639,"user":{"displayName":"Dhruuv Agarwal","photoUrl":"","userId":"01407691864159926745"}},"colab":{"base_uri":"https://localhost:8080/","height":555}},"source":["!pip install librosa # in colab, you’ll need to install this\n","import librosa\n","s, sr=librosa.load('train_clean_male.wav', sr=None)\n","Sdata=librosa.stft(s, n_fft=1024, hop_length=512)\n","sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n","Xdata1=librosa.stft(sn, n_fft=1024, hop_length=512)\n","Xdata2 = np.abs(Xdata1.T)\n","Sdata = np.abs(Sdata.T)\n","\n","snt, srt=librosa.load('test_x_01.wav', sr=None)\n","Xtest=librosa.stft(snt, n_fft=1024, hop_length=512)\n","Xtestm = np.abs(Xtest.T)\n","\n","snt2, srt2=librosa.load('test_x_02.wav', sr=None)\n","Xtest2=librosa.stft(snt2, n_fft=1024, hop_length=512)\n","Xtestm2 = np.abs(Xtest2.T)\n","\n","print(Xdata2.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.16.3)\n","Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.2.1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n","Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-da09459e8419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install librosa # in colab, you’ll need to install this'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_clean_male.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mSdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_dirty_male.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train_clean_male.wav'"]}]},{"cell_type":"code","metadata":{"id":"kjqmccYZ4QWe","colab_type":"code","colab":{}},"source":["Xinp = tf.placeholder('float',[None,513])\n","yinp = tf.placeholder('float',[None,513])\n","y = tf.placeholder('float')\n","is_training = tf.placeholder(tf.bool)\n","\n","from sklearn.model_selection import train_test_split\n","\n","Xdata,Xval,Sdata,Sval = train_test_split(Xdata2,Sdata,test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fx7wtKAHv0IX","colab_type":"text"},"source":["Below are the initial default parameters defined which will be changed later."]},{"cell_type":"code","metadata":{"id":"9jZVrB_lp9mo","colab_type":"code","colab":{}},"source":["output = []\n","output2 = []\n","batch_size = 128\n","\n","def cnn_model_fn(Xinp,yinp,mode):\n","  global output \n","  global output2\n","  global batch_size\n","  \"\"\"Model function for CNN.\"\"\"\n","  # Input Layer\n","  input_layer = tf.reshape(Xinp, [-1, 1,1,513])\n","\n","  initconv = tf.contrib.layers.variance_scaling_initializer(uniform=False,factor=2.0)\n","  # Convolutional Layer #1\n","  conv1 = tf.layers.conv2d(\n","      inputs=input_layer,\n","      filters=32,\n","      kernel_size=[1, 9],\n","      padding=\"same\",\n","      activation=None,\n","      data_format = 'channels_first'\n","  )#kernel_initializer=initconv)\n","  conv1_bn_relu = tf.nn.relu(conv1)\n","  # Pooling Layer #1\n","  pool1 = tf.layers.max_pooling2d(inputs=conv1_bn_relu, pool_size=[1, 2], strides=[1,2],data_format = 'channels_first')\n","\n","  # Convolutional Layer #2 and Pooling Layer #2\n","  conv2 = tf.layers.conv2d(\n","      inputs=pool1,\n","      filters=64,\n","      kernel_size=[1, 5],\n","      padding=\"same\",\n","      activation=tf.nn.relu,\n","      data_format = 'channels_first'\n","  )#kernel_initializer=initconv)\n","  \n","  \n","  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[1, 2], strides=[1,2],data_format = 'channels_first')\n","  init = tf.contrib.layers.variance_scaling_initializer(uniform=True,factor=1.0)\n","  # Dense Layer\n","  pool2_flat = tf.reshape(pool2, [-1, 1 * 128 * 64])\n","  dense = tf.layers.dense(inputs=pool2_flat, units=2048, activation=tf.nn.relu)#,kernel_initializer=init,bias_initializer=init)#,data_format = 'channels_first')\n","  dropout = tf.layers.dropout(inputs=dense, rate=0.3,training=is_training)\n","  \n","  out = tf.layers.dense(inputs=dropout, units=513, activation=tf.nn.relu)#,kernel_initializer=init,bias_initializer=init)\n","  mse = tf.losses.mean_squared_error(labels=yinp, predictions = out)\n","  \n","  \n","  # Configure the Training Op (for TRAIN mode)\n","  \n","  optimizer = tf.train.AdamOptimizer(learning_rate=0.0004).minimize(mse)\n","    \n","  if mode == 'TRAIN':\n","    n_epochs = 1000\n","\n","\n","    with tf.Session() as sess:\n","      sess.run(tf.global_variables_initializer())\n","      \n","      for epoch in range(n_epochs):\n","        \n","        rand_index = np.random.choice(Xdata.shape[0], size=batch_size)\n","        np.random.shuffle(rand_index)\n","        res=[]\n","        #print(Xdata.shape[0])\n","        #print(rand_index)\n","        loss = 0\n","        for i in range(0,int(len(Xdata)/batch_size)):   \n","          vals =rand_index[i*batch_size:(i+1)*batch_size]\n","          xbatch = Xdata[vals]\n","          sbatch = Sdata[vals]\n","          res = sess.run([optimizer,mse],feed_dict={Xinp:xbatch,yinp:sbatch,is_training:True})\n","          loss+=res[1]\n","          last= (i+1)*batch_size\n","        \n","        xbatch = Xdata[rand_index[last:]]\n","        sbatch = Sdata[rand_index[last:]]\n","        #print(xbatch.shape)\n","        \n","        if len(xbatch)>1:\n","          res = sess.run([optimizer,mse],feed_dict={Xinp:xbatch,yinp:sbatch,is_training:True})\n","          loss += res[1]\n","        if epoch%10==0:\n","          print('Epoch',epoch,' out of ',n_epochs,' loss:',loss)\n","          tmp = sess.run(out,feed_dict = {Xinp:Xdata2, is_training:False})\n","          #print(Xdata2.shape,tmp.shape)\n","          sht = (Xdata1/Xdata2.T)*tmp.T\n","          iSt = librosa.istft(sht, hop_length=512)\n","          print(\"snr: \",getSNR(s,iSt))\n","      output = sess.run(out,feed_dict = {Xinp:Xtestm, is_training:False})\n","      output2 = sess.run(out,feed_dict = {Xinp:Xtestm2, is_training:False})\n","      print(\"val loss:\",sess.run(mse,feed_dict = {Xinp:Xval, yinp:Sval,is_training:False}))\n","        #mseval = sess.run(mse,feed_dict = {Xinp:Xval,y:Sval})\n","      \n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EVswDidWT1I","colab_type":"code","colab":{}},"source":["#setparam(2,1024,513,513,100)\n","cnn_model_fn(Xinp,yinp,'TRAIN')\n","print(output2.shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VK7-RLs9wVTg","colab_type":"text"},"source":["We see the SNR ends up to be 14.5-15 approx in 1000 epochs. \n","\n","Also as we needed positive values at the end we have chosen relu activation at the last layer. \n","The structure is 2 conv layer network with 1d filters (32 filters 1x9 and 64 filters 1x5) with maxpooling after both and 2048 units in following dense layer, finally a dense output layer. And the the leanrning rate was selected to be 0.0004. \n","\n","After this we get the Matrices learnt from the trained model and the Test input data, and convert them to get back the phase information as below.\n","\n","This enables us to use istft and get the reconstructed version of the sound signal."]},{"cell_type":"code","metadata":{"id":"_f_-pB5hBVcZ","colab_type":"code","colab":{}},"source":["shtest1 = (Xtest/Xtestm.T)*output.T\n","shtest2 = (Xtest2/Xtestm2.T)*output2.T\n","print(shtest1.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KiCGEMYYSTEF","colab":{}},"source":["#snt, srt=librosa.load('test_x_01.wav', sr=None)\n","#snt2, srt2=librosa.load('test_x_02.wav', sr=None)\n","\n","#Xtest=librosa.stft(snt, n_fft=1024, hop_length=512)\n","iStftMat1 = librosa.istft(shtest1, hop_length=512)\n","iStftMat2 = librosa.istft(shtest2, hop_length=512)\n","\n","\n","librosa.output.write_wav('test_s_01_recons.wav', iStftMat1, srt)\n","librosa.output.write_wav('test_s_02_recons.wav', iStftMat2, srt2)"],"execution_count":0,"outputs":[]}]}