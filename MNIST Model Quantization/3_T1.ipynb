{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_T1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"m61cudLC_NUz","colab_type":"text"},"source":[" Network compression for mnist model"]},{"cell_type":"code","metadata":{"id":"T3mZ04777o3j","colab_type":"code","outputId":"74b88e8f-0596-4ccc-f74d-a362f760b2cd","colab":{"base_uri":"https://localhost:8080/","height":524}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-e3e0b6827f22>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qJeEqAMd7xJ-","colab_type":"code","colab":{}},"source":["n_hiddenlayer = 5\n","n_hiddenunits = 1024\n","n_classes = 10\n","n_inpsize = 784\n","batch_size = 128\n","\n","Xinp = tf.placeholder('float',[None,n_inpsize])\n","y = tf.placeholder('float')\n","is_training = tf.placeholder(tf.bool)\n","\n","last = []"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EX5HN0hf9Su6","colab_type":"text"},"source":["Below the fully connected model with no queantization is made"]},{"cell_type":"code","metadata":{"id":"T_1sncT5-C4v","colab_type":"code","colab":{}},"source":["def FC_graph(data):\n","  init = tf.contrib.layers.variance_scaling_initializer(uniform=True,factor=1.0)\n","  \n","  layer1 = tf.layers.dense(inputs=data, units=1024, activation=tf.nn.relu,name='layer1')#,kernel_initializer=init,bias_initializer=init)\n","  #dropout1 = tf.layers.dropout(inputs=layer1, rate=0.3,training=is_training)\n","  layer2 = tf.layers.dense(inputs=layer1, units=1024, activation=tf.nn.relu,name='layer2')#,kernel_initializer=init,bias_initializer=init)\n","  layer3 = tf.layers.dense(inputs=layer2, units=1024, activation=tf.nn.relu,name='layer3')#,kernel_initializer=init,bias_initializer=init)\n","  #dropout2 = tf.layers.dropout(inputs=layer3, rate=0.3,training=is_training)\n","  layer4 = tf.layers.dense(inputs=layer3, units=1024, activation=tf.nn.relu,name='layer4')#,kernel_initializer=init,bias_initializer=init)\n","  layer5 = tf.layers.dense(inputs=layer4, units=1024, activation=tf.nn.relu,name='layer5')#,kernel_initializer=init,bias_initializer=init)\n","  out = tf.layers.dense(inputs=layer5, units=10, activation=None,name='out')\n","  return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T9uCeb3d9aHM","colab_type":"text"},"source":["For the quantization we are using SVD to get shorter versions of weight matrix but now we have two of them in form of U and V. So to incorporate this as in 1.6a, I have used subclass for dense layer to have U and V as its variables."]},{"cell_type":"code","metadata":{"id":"6R8TJc5pjNBK","colab_type":"code","colab":{}},"source":["def actnone(x):\n","  return x\n","class MyDenseLayer(tf.keras.layers.Layer):\n","  def __init__(self, input, num_outputs,activation=actnone,Uinit= None, Vinit =None, biasinit= None):\n","    super(MyDenseLayer, self).__init__()\n","    self.num_outputs = num_outputs\n","    self.activation= activation \n","    print(self.activation)\n","    self.U = self.add_variable(\"U\", shape=[int(input.shape[-1]), int(input.shape[-1])])\n","    self.V = self.add_variable(\"V\", shape=[int(input.shape[-1]), self.num_outputs])\n","    init = tf.contrib.layers.variance_scaling_initializer(uniform=True,factor=2.0)\n","    self.bias = self.add_variable(\"bias\", shape=[self.num_outputs],dtype=tf.float32,initializer=init)#tf.zeros_initializer())\n","    if Uinit is not None: self.U = Uinit\n","    if Vinit is not None: self.V = Vinit\n","    \n","    print()\n","    \n","  def build(self ):\n","    pass\n","    \n","  def call(self, input):\n","    if self.activation is not None: return self.activation( tf.add(tf.matmul(input, self.U @ self.V), self.bias))\n","    return tf.add(tf.matmul(input, self.U @ self.V), self.bias)\n","def mod_graph(data):  \n","  mlayer1 = MyDenseLayer(data,1024,tf.nn.relu,Uinit=s[0][:,:20],Vinit=np.diag(u[0][:20])@v[0][:20,:])\n","  l1 = mlayer1.call(data)\n","  mlayer2 = MyDenseLayer(l1,1024,tf.nn.relu,Uinit=s[1][:,:20],Vinit=np.diag(u[1][:20])@v[1][:20,:])\n","  l2 = mlayer2.call(l1)\n","  mlayer3 = MyDenseLayer(l2,1024,tf.nn.relu,Uinit=s[2][:,:20],Vinit=np.diag(u[2][:20])@v[2][:20,:])\n","  l3 = mlayer3.call(l2)\n","  mlayer4 = MyDenseLayer(l3,1024,tf.nn.relu,Uinit=s[3][:,:20],Vinit=np.diag(u[3][:20])@v[3][:20,:])\n","  l4 = mlayer4.call(l3)\n","  mlayer5 = MyDenseLayer(l4,1024,tf.nn.relu,Uinit=s[4][:,:20],Vinit=np.diag(u[4][:20])@v[4][:20,:])\n","  l5 = mlayer5.call(l4)\n","  mout = MyDenseLayer(l5, 10, activation=None,Uinit=a[0],Vinit=np.diag(b[0])@c[0])\n","  #print(mlayer1(mnist.train.images))\n","  print(mlayer1.trainable_variables)\n","  return mout.call(l5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4WB8Vf3LCGYG","colab_type":"code","colab":{}},"source":["weights = [[] for i in range(5)]\n","\n","def train_nn(X,epochs,lr,fn=\"old\"):\n","  global weights, last\n","  pred = FC_graph(X) if fn==\"old\" else mod_graph(X)\n","  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n","  optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n","  \n","  n_epochs = epochs\n","  \n","  with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    correct = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n","    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n","    for epoch in range(n_epochs):\n","      loss = 0\n","      for i in range(int(mnist.train.num_examples/batch_size)):\n","        ex,ey = mnist.train.next_batch(batch_size)\n","        _,c = sess.run([optimizer,cost],feed_dict={Xinp:ex,y:ey,is_training :True})\n","        loss += c\n","      print('Epoch',epoch,' out of ',n_epochs,' loss:',loss)\n","      print('accuracy:',accuracy.eval({Xinp:mnist.test.images[100:200],y:mnist.test.labels[100:200],is_training :False}))\n","    for i in range(5):\n","      weights[i] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'layer'+str(i+1)+'/kernel:0'))\n","    last = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'out'+'/kernel:0'))\n","    print(weights[1])\n","    #with tf.variable_scope('layer1', reuse=True):\n","      #tf.get_variable('weights')\n","    #output  = pred\n","\n","    #layer = sess.run(layers[-1])\n","    print('accuracy:',accuracy.eval({Xinp:mnist.test.images,y:mnist.test.labels,is_training :False}))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nq6LUSVUCjNf","colab_type":"code","outputId":"8cd81321-972b-4743-f4bc-9c15046ff3c6","colab":{"base_uri":"https://localhost:8080/","height":2154}},"source":["train_nn(Xinp,50,0.0001)\n","a,b,c =  np.linalg.svd(last,full_matrices=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-9dbf338cb4f2>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-5-fe48d6639c38>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Epoch 0  out of  50  loss: 141.63526622205973\n","accuracy: 0.97\n","Epoch 1  out of  50  loss: 46.76544467546046\n","accuracy: 0.99\n","Epoch 2  out of  50  loss: 28.42932279035449\n","accuracy: 0.99\n","Epoch 3  out of  50  loss: 18.752889033872634\n","accuracy: 0.99\n","Epoch 4  out of  50  loss: 13.369068400235847\n","accuracy: 0.97\n","Epoch 5  out of  50  loss: 8.854499636683613\n","accuracy: 0.98\n","Epoch 6  out of  50  loss: 6.062992651248351\n","accuracy: 0.98\n","Epoch 7  out of  50  loss: 5.1776374957407825\n","accuracy: 0.99\n","Epoch 8  out of  50  loss: 5.860763416363625\n","accuracy: 0.98\n","Epoch 9  out of  50  loss: 4.171576724751503\n","accuracy: 0.96\n","Epoch 10  out of  50  loss: 4.627888468829042\n","accuracy: 0.97\n","Epoch 11  out of  50  loss: 2.7793525513152417\n","accuracy: 0.98\n","Epoch 12  out of  50  loss: 3.240072767701349\n","accuracy: 0.98\n","Epoch 13  out of  50  loss: 2.9372471052975015\n","accuracy: 0.97\n","Epoch 14  out of  50  loss: 3.6294220062354725\n","accuracy: 0.98\n","Epoch 15  out of  50  loss: 1.4314985849669029\n","accuracy: 0.99\n","Epoch 16  out of  50  loss: 2.9396728818865085\n","accuracy: 0.98\n","Epoch 17  out of  50  loss: 2.519952629765612\n","accuracy: 0.98\n","Epoch 18  out of  50  loss: 2.335985388447625\n","accuracy: 0.98\n","Epoch 19  out of  50  loss: 0.6610693554571299\n","accuracy: 0.96\n","Epoch 20  out of  50  loss: 4.332492289668153\n","accuracy: 0.98\n","Epoch 21  out of  50  loss: 1.849454060991775\n","accuracy: 0.99\n","Epoch 22  out of  50  loss: 1.9526975138778653\n","accuracy: 0.99\n","Epoch 23  out of  50  loss: 2.3574340284285427\n","accuracy: 0.98\n","Epoch 24  out of  50  loss: 3.035292694145028\n","accuracy: 0.98\n","Epoch 25  out of  50  loss: 1.0997570326853747\n","accuracy: 0.97\n","Epoch 26  out of  50  loss: 2.0491057476383503\n","accuracy: 0.96\n","Epoch 27  out of  50  loss: 0.9938028363317244\n","accuracy: 0.97\n","Epoch 28  out of  50  loss: 1.3230149967987472\n","accuracy: 0.97\n","Epoch 29  out of  50  loss: 2.688803077531702\n","accuracy: 0.99\n","Epoch 30  out of  50  loss: 1.1538357463127795\n","accuracy: 0.96\n","Epoch 31  out of  50  loss: 1.131319531527879\n","accuracy: 0.98\n","Epoch 33  out of  50  loss: 0.02236142795231899\n","accuracy: 0.97\n","Epoch 34  out of  50  loss: 0.005256586589013068\n","accuracy: 0.98\n","Epoch 35  out of  50  loss: 0.0022789060058308053\n","accuracy: 0.98\n","Epoch 36  out of  50  loss: 0.0012843933583290834\n","accuracy: 0.98\n","Epoch 37  out of  50  loss: 0.0008575126578165282\n","accuracy: 0.98\n","Epoch 38  out of  50  loss: 0.0006371162191083357\n","accuracy: 0.98\n","Epoch 39  out of  50  loss: 0.000509082937432126\n","accuracy: 0.98\n","Epoch 40  out of  50  loss: 0.0004011092126026128\n","accuracy: 0.98\n","Epoch 41  out of  50  loss: 0.0003189887283348014\n","accuracy: 0.98\n","Epoch 42  out of  50  loss: 0.0002527081351376692\n","accuracy: 0.98\n","Epoch 43  out of  50  loss: 0.0002149642158161269\n","accuracy: 0.98\n","Epoch 44  out of  50  loss: 0.0001733466758004898\n","accuracy: 0.98\n","Epoch 45  out of  50  loss: 0.00014004669083234056\n","accuracy: 0.98\n","Epoch 46  out of  50  loss: 0.00011448290278537332\n","accuracy: 0.98\n","Epoch 47  out of  50  loss: 9.215410293117454e-05\n","accuracy: 0.98\n","Epoch 48  out of  50  loss: 7.665449934007862e-05\n","accuracy: 0.98\n","Epoch 49  out of  50  loss: 6.090241112999273e-05\n","accuracy: 0.98\n","[array([[ 4.8243504e-02, -4.2061295e-02, -2.6819622e-02, ...,\n","         3.6820721e-02, -2.7902303e-02,  1.5688110e-02],\n","       [-2.6136616e-03,  2.5787253e-02,  7.2674945e-02, ...,\n","        -5.5696950e-03, -5.3388778e-02, -5.5931234e-03],\n","       [-1.7045880e-02, -5.1989023e-02, -1.1989482e-02, ...,\n","        -2.3363829e-02, -3.8882088e-02,  3.5993371e-02],\n","       ...,\n","       [ 1.7194964e-02, -2.5881561e-02, -5.7046298e-02, ...,\n","        -3.4841526e-02, -6.7091421e-03,  4.6084802e-05],\n","       [-3.9348099e-02, -2.5869153e-02, -2.3888756e-02, ...,\n","         5.3621914e-02, -6.3296281e-02, -1.6657844e-02],\n","       [-1.4366108e-02, -2.4548620e-02,  2.9704945e-02, ...,\n","         3.4677934e-02, -1.0241370e-02,  5.2500676e-02]], dtype=float32)]\n","accuracy: 0.9846\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tZm8io-uLrvK","colab_type":"code","colab":{}},"source":["s ,u,v = {},{},{}\n","for i in range(5):\n"," s[i],u[i],v[i] =  np.linalg.svd(weights[i][0],full_matrices=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K0Z0GZyN91dq","colab_type":"text"},"source":["Below the  trimmed matrices for different values of D and the respective SVD values are used to find the weights to get the accuracy comparison. "]},{"cell_type":"code","metadata":{"id":"_iDzA8XCp6na","colab_type":"code","colab":{}},"source":["D=[10,20,50,100,200]\n","op={}\n","for i in range(5):\n","  for d in D:\n","    op[i,d] = s[i][:,:d] @ np.diag(u[i][:d]) @v[i][:d,:]\n","  op[i,9999] = s[i] @ np.diag(u[i]) @v[i]    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwMBQHDO58o2","colab_type":"code","colab":{}},"source":["x = np.random.random((5000, 5000)) - 0.5\n","\n","def rel(x):\n","  return np.maximum(x, 0)\n","def getacc(w):\n","  acc = (rel (rel (rel (rel (rel(mnist.test.images @ w[0]) @ w[1]) @ w[2]) @ w[3]) @ w[4]) @ last)\n","  correct = np.equal(np.argmax(acc[0],1),np.argmax(mnist.test.labels,1))\n","  return np.mean(correct)\n","accs= []\n","D.append(9999)\n","for d in D:\n","  w = [op[i,d] for i in range(5)]\n","  accs.append(getacc(w))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FbBQs74-LGj","colab_type":"text"},"source":["In the graph the x label 9999 refers to full D value. we can see as the quantization is less strict we get more accurate results."]},{"cell_type":"code","metadata":{"id":"WREVOjB2CpGq","colab_type":"code","outputId":"96e86cf9-3027-4e19-94bf-0ed0d28f5fc1","colab":{"base_uri":"https://localhost:8080/","height":381}},"source":["print(accs)\n","import seaborn as sns\n","sns.barplot(x=D,y=accs)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.7314, 0.916, 0.9504, 0.9677, 0.9772, 0.9848]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f48280fff98>"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRogwAABGiDAAAEb+D8hB12cWbkmQAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IKbcnWJYoz11","colab_type":"code","outputId":"4a1f1841-dbec-44e3-a703-3367bb3ad206","colab":{"base_uri":"https://localhost:8080/","height":1478}},"source":["batch_size = 10\n","train_nn(Xinp,30,0.0003,\"new\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<function relu at 0x7f48374d67b8>\n","\n","<function relu at 0x7f48374d67b8>\n","\n","<function relu at 0x7f48374d67b8>\n","\n","<function relu at 0x7f48374d67b8>\n","\n","<function relu at 0x7f48374d67b8>\n","\n","None\n","\n","[<tf.Variable 'U:0' shape=(784, 784) dtype=float32>, <tf.Variable 'V:0' shape=(784, 1024) dtype=float32>, <tf.Variable 'bias:0' shape=(1024,) dtype=float32>]\n","Epoch 0  out of  30  loss: 1466.4734708192027\n","accuracy: 0.97\n","Epoch 1  out of  30  loss: 749.9347237775177\n","accuracy: 0.98\n","Epoch 2  out of  30  loss: 618.6078517611861\n","accuracy: 0.98\n","Epoch 3  out of  30  loss: 549.5400302238461\n","accuracy: 0.98\n","Epoch 4  out of  30  loss: 518.1116290755598\n","accuracy: 0.98\n","Epoch 5  out of  30  loss: 496.20580851790146\n","accuracy: 0.98\n","Epoch 6  out of  30  loss: 479.72743784606155\n","accuracy: 0.98\n","Epoch 7  out of  30  loss: 452.32058644849167\n","accuracy: 0.98\n","Epoch 8  out of  30  loss: 448.622467947489\n","accuracy: 0.97\n","Epoch 9  out of  30  loss: 449.19941635737814\n","accuracy: 0.98\n","Epoch 10  out of  30  loss: 440.53655268212606\n","accuracy: 0.98\n","Epoch 11  out of  30  loss: 428.37375114288307\n","accuracy: 0.98\n","Epoch 12  out of  30  loss: 425.1411377508548\n","accuracy: 0.98\n","Epoch 13  out of  30  loss: 422.5116918918975\n","accuracy: 0.98\n","Epoch 14  out of  30  loss: 418.8841953511792\n","accuracy: 0.98\n","Epoch 15  out of  30  loss: 411.35752261492235\n","accuracy: 0.98\n","Epoch 16  out of  30  loss: 418.07523647030393\n","accuracy: 0.98\n","Epoch 17  out of  30  loss: 403.591127202852\n","accuracy: 0.98\n","Epoch 18  out of  30  loss: 407.9359742049178\n","accuracy: 0.98\n","Epoch 19  out of  30  loss: 407.72475343106817\n","accuracy: 0.98\n","Epoch 20  out of  30  loss: 404.6303997136356\n","accuracy: 0.98\n","Epoch 21  out of  30  loss: 400.6783917534167\n","accuracy: 0.97\n","Epoch 22  out of  30  loss: 392.77728666192525\n","accuracy: 0.98\n","Epoch 23  out of  30  loss: 400.8360551477517\n","accuracy: 0.98\n","Epoch 24  out of  30  loss: 395.9503790619983\n","accuracy: 0.98\n","Epoch 25  out of  30  loss: 392.6041021447545\n","accuracy: 0.98\n","Epoch 26  out of  30  loss: 398.73424420911397\n","accuracy: 0.98\n","Epoch 27  out of  30  loss: 392.20939447941964\n","accuracy: 0.98\n","Epoch 28  out of  30  loss: 390.28096966996964\n","accuracy: 0.98\n","Epoch 29  out of  30  loss: 395.9939227866894\n","accuracy: 0.98\n","[array([[ 0.03623274,  0.05389693,  0.00388547, ..., -0.00172677,\n","         0.05114567, -0.05209572],\n","       [ 0.01579151,  0.00022858,  0.04259353, ...,  0.01722026,\n","        -0.04231164,  0.04019694],\n","       [ 0.00994677, -0.05336817,  0.00569296, ...,  0.0144231 ,\n","        -0.0539987 , -0.00643395],\n","       ...,\n","       [ 0.04987641, -0.01811997, -0.02138105, ..., -0.05151992,\n","         0.01113782, -0.03722534],\n","       [ 0.02677441,  0.01909498,  0.01382758, ...,  0.02009901,\n","        -0.02268874,  0.04460214],\n","       [ 0.01805164, -0.05130295, -0.02084454, ..., -0.02878408,\n","         0.02881143, -0.00877187]], dtype=float32)]\n","accuracy: 0.9684\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ATN3ueKuFDar","colab_type":"code","outputId":"23aa50ac-8a2b-4849-c702-1de58cfb59a5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a.shape,b.shape,c.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1, 1024, 10), (1, 10), (1, 10, 10))"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"pjMJmAJJvl7p","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}